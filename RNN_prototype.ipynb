{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_prototype.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLKAmwY51lBRDm2dt451/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyjoon001/EEE4178/blob/main/RNN_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "523FIIUegjP9"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUqsc5IVgnxG"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 10\n",
        "num_classes = 10\n",
        "batch_size = 50\n",
        "num_epochs = 3\n",
        "learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqNMIDYhhHSF"
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_dgGWrggohz",
        "outputId": "bab31243-7b27-4d0a-b534-c6cd47475f91"
      },
      "source": [
        "train_data = torchvision.datasets.MNIST(root='./datasets',\n",
        "                                        train=True,\n",
        "                                        transform=transforms.ToTensor(),\n",
        "                                        download=True)\n",
        "test_data = torchvision.datasets.MNIST(root='./datasets',\n",
        "                                        train=False,\n",
        "                                        transform=transforms.ToTensor(),\n",
        "                                        download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZyI5Dk_hI7F"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkgeVC0DhLJa"
      },
      "source": [
        "# cf) Check dataloader shape\n",
        "image, label = next(iter(test_loader))\n",
        "print(image.size()) # [Batch, Channel, Height, Width]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suGMDlRegp1j"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCJTyuXPgsOy"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, intput_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # set initial hidden states and cell states\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # torch.size([2, 50, 128])\n",
        "    c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # torch.size([2, 50, 128])\n",
        "\n",
        "    #Forward propagate LSTM\n",
        "    out, _  = self.lstm(x, (h0, c0)) # output: tensor [batch_size, seq_length, hidden_size]\n",
        "\n",
        "    #Decode the hidden state of the last time step\n",
        "    out = self.fc(out[:,-1,:])\n",
        "\n",
        "    return out\n",
        "\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf4M7H6ngt5L"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OIRQUMfgu6k",
        "outputId": "e7b4b739-4ab1-481d-f198-3170b4907a32"
      },
      "source": [
        "####### Train #######\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (image, label) in enumerate(train_loader):\n",
        "    image = image.reshape(-1, sequence_length, input_size).to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Forward\n",
        "    output = model(image)\n",
        "    loss = criterion(output, label)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) % 100 == 0:\n",
        "      print(\"Epoch [{}/{}], Step[{}/{}], Loss:{:.4f}\".format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Step[100/1200], Loss:2.1105\n",
            "Epoch [1/3], Step[200/1200], Loss:1.7216\n",
            "Epoch [1/3], Step[300/1200], Loss:1.2655\n",
            "Epoch [1/3], Step[400/1200], Loss:1.5544\n",
            "Epoch [1/3], Step[500/1200], Loss:1.4535\n",
            "Epoch [1/3], Step[600/1200], Loss:1.5671\n",
            "Epoch [1/3], Step[700/1200], Loss:1.5063\n",
            "Epoch [1/3], Step[800/1200], Loss:1.5551\n",
            "Epoch [1/3], Step[900/1200], Loss:1.5996\n",
            "Epoch [1/3], Step[1000/1200], Loss:1.2172\n",
            "Epoch [1/3], Step[1100/1200], Loss:1.2952\n",
            "Epoch [1/3], Step[1200/1200], Loss:2.3168\n",
            "Epoch [2/3], Step[100/1200], Loss:2.2919\n",
            "Epoch [2/3], Step[200/1200], Loss:2.3120\n",
            "Epoch [2/3], Step[300/1200], Loss:2.2868\n",
            "Epoch [2/3], Step[400/1200], Loss:2.2999\n",
            "Epoch [2/3], Step[500/1200], Loss:2.3644\n",
            "Epoch [2/3], Step[600/1200], Loss:2.2960\n",
            "Epoch [2/3], Step[700/1200], Loss:2.2842\n",
            "Epoch [2/3], Step[800/1200], Loss:2.2931\n",
            "Epoch [2/3], Step[900/1200], Loss:2.2944\n",
            "Epoch [2/3], Step[1000/1200], Loss:2.3085\n",
            "Epoch [2/3], Step[1100/1200], Loss:2.2841\n",
            "Epoch [2/3], Step[1200/1200], Loss:2.3150\n",
            "Epoch [3/3], Step[100/1200], Loss:2.3140\n",
            "Epoch [3/3], Step[200/1200], Loss:2.2949\n",
            "Epoch [3/3], Step[300/1200], Loss:2.2994\n",
            "Epoch [3/3], Step[400/1200], Loss:2.3258\n",
            "Epoch [3/3], Step[500/1200], Loss:2.3137\n",
            "Epoch [3/3], Step[600/1200], Loss:2.2859\n",
            "Epoch [3/3], Step[700/1200], Loss:2.2954\n",
            "Epoch [3/3], Step[800/1200], Loss:2.3155\n",
            "Epoch [3/3], Step[900/1200], Loss:2.2929\n",
            "Epoch [3/3], Step[1000/1200], Loss:2.3174\n",
            "Epoch [3/3], Step[1100/1200], Loss:2.2910\n",
            "Epoch [3/3], Step[1200/1200], Loss:2.3206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHuKdUlvgwLT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}